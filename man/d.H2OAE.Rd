% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/d.H2OAE.R
\name{d.H2OAE}
\alias{d.H2OAE}
\title{Autoencoder using H2O}
\usage{
d.H2OAE(
  x,
  x.test = NULL,
  x.valid = NULL,
  ip = "localhost",
  port = 54321,
  n.hidden.nodes = c(ncol(x), 3, ncol(x)),
  extract.layer = ceiling(length(n.hidden.nodes)/2),
  epochs = 5000,
  activation = "Tanh",
  loss = "Automatic",
  input.dropout.ratio = 0,
  hidden.dropout.ratios = rep(0, length(n.hidden.nodes)),
  learning.rate = 0.005,
  learning.rate.annealing = 1e-06,
  l1 = 0,
  l2 = 0,
  stopping.rounds = 50,
  stopping.metric = "AUTO",
  scale = TRUE,
  center = TRUE,
  n.cores = rtCores,
  verbose = TRUE,
  save.mod = FALSE,
  outdir = NULL,
  ...
)
}
\arguments{
\item{x}{Vector / Matrix / Data Frame: Training set Predictors}

\item{x.test}{Vector / Matrix / Data Frame: Testing set Predictors}

\item{x.valid}{Vector / Matrix / Data Frame: Validation set Predictors}

\item{ip}{Character: IP address of H2O server. Default = "localhost"}

\item{port}{Integer: Port number for server. Default = 54321}

\item{n.hidden.nodes}{Integer vector of length equal to the number of hidden layers you wish to create}

\item{extract.layer}{Integer: Which layer to extract. For regular autoencoder, this is the middle layer.
Default = \code{ceiling(length(n.hidden.nodes)/2)}}

\item{epochs}{Integer: How many times to iterate through the dataset. Default = 5000}

\item{activation}{Character: Activation function to use: "Tanh" (Default), "TanhWithDropout", "Rectifier", "RectifierWithDropout",
"Maxout", "MaxoutWithDropout"}

\item{loss}{Character: "Automatic" (Default), "CrossEntropy", "Quadratic", "Huber", "Absolute"}

\item{input.dropout.ratio}{Float (0, 1): Dropout ratio for inputs}

\item{hidden.dropout.ratios}{Vector, Float (0, 2): Dropout ratios for hidden layers}

\item{learning.rate}{Float: Learning rate. Default = .005}

\item{learning.rate.annealing}{Float: Learning rate annealing. Default = 1e-06}

\item{l1}{Float (0, 1): L1 regularization
(introduces sparseness; i.e. sets many weights to 0; reduces variance, increases generalizability)}

\item{l2}{Float (0, 1): L2 regularization
(prevents very large absolute weights; reduces variance, increases generalizability)}

\item{stopping.rounds}{Integer: Stop if simple moving average of length \code{stopping.rounds} of the
\code{stopping.metric} does not improve. Set to 0 to disable. Default = 50}

\item{stopping.metric}{Character: Stopping metric to use: "AUTO", "deviance", "logloss", "MSE", "RMSE", "MAE", "RMSLE",
"AUC", "lift_top_group", "misclassification", "mean_per_class_error". Default = "AUTO" ("logloss" for Classification,
"deviance" for Regression)}

\item{scale}{Logical: If TRUE, scale input before training autoencoder. Default = TRUE}

\item{center}{Logical: If TRUE, center input before training autoencoder. Default = TRUE}

\item{n.cores}{Integer: Number of cores to use}

\item{verbose}{Logical: If TRUE, print summary to screen.}

\item{save.mod}{Logical: If TRUE, save all output to an RDS file in \code{outdir}
\code{save.mod} is TRUE by default if an \code{outdir} is defined. If set to TRUE, and no \code{outdir}
is defined, outdir defaults to \code{paste0("./s.", mod.name)}}

\item{outdir}{Path to output directory.
If defined, will save Predicted vs. True plot, if available,
as well as full model output, if \code{save.mod} is TRUE}

\item{...}{Additional arguments to pass to \code{h2p::h2o.deeplearning}}
}
\value{
\link{rtDecom} object
}
\description{
Train an Autoencoder using \code{h2o::h2o.deeplearning}
Check out the H2O Flow at \code{[ip]:[port]}, Default IP:port is "localhost:54321"
e.g. if running on localhost, point your web browser to \code{localhost:54321}
}
\seealso{
\link{decom}

Other Decomposition: 
\code{\link{d.CUR}()},
\code{\link{d.H2OGLRM}()},
\code{\link{d.ICA}()},
\code{\link{d.ISOMAP}()},
\code{\link{d.KPCA}()},
\code{\link{d.LLE}()},
\code{\link{d.MDS}()},
\code{\link{d.NMF}()},
\code{\link{d.PCA}()},
\code{\link{d.SPCA}()},
\code{\link{d.SVD}()},
\code{\link{d.TSNE}()},
\code{\link{d.UMAP}()}

Other Deep Learning: 
\code{\link{p.MXINCEPTION}()},
\code{\link{s.H2ODL}()},
\code{\link{s.MXN}()},
\code{\link{s.TFN}()}
}
\author{
Efstathios D. Gennatas
}
\concept{Decomposition}
\concept{Deep Learning}
