% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/01_S7_Hyperparameters.R
\name{setup_LightRF}
\alias{setup_LightRF}
\title{Setup LightRF Hyperparameters}
\usage{
setup_LightRF(
  nrounds = 500L,
  num_leaves = 4096L,
  max_depth = -1L,
  feature_fraction = 0.7,
  subsample = 0.623,
  lambda_l1 = 0,
  lambda_l2 = 0,
  max_cat_threshold = 32L,
  min_data_per_group = 32L,
  linear_tree = FALSE,
  ifw = FALSE,
  objective = NULL,
  device_type = "cpu",
  tree_learner = "serial",
  force_col_wise = TRUE,
  num_threads = 0L
)
}
\arguments{
\item{nrounds}{(Tunable) Positive integer: Number of boosting rounds.}

\item{num_leaves}{(Tunable) Positive integer: Maximum number of leaves in one tree.}

\item{max_depth}{(Tunable) Integer: Maximum depth of trees.}

\item{feature_fraction}{(Tunable) Numeric: Fraction of features to use.}

\item{subsample}{(Tunable) Numeric: Fraction of data to use.}

\item{lambda_l1}{(Tunable) Numeric: L1 regularization.}

\item{lambda_l2}{(Tunable) Numeric: L2 regularization.}

\item{max_cat_threshold}{(Tunable) Positive integer: Maximum number of categories for categorical features.}

\item{min_data_per_group}{(Tunable) Positive integer: Minimum number of data per categorical group.}

\item{linear_tree}{Logical: If TRUE, use linear trees.}

\item{ifw}{Logical: If TRUE, use Inverse Frequency Weighting in classification.}

\item{objective}{Character: Objective function.}

\item{device_type}{Character: "cpu" or "gpu".}

\item{tree_learner}{Character: "serial", "feature", "data", or "voting".}

\item{force_col_wise}{Logical: Use only with CPU - If TRUE, force col-wise histogram building}

\item{num_threads}{Integer: Number of threads to use. 0 means default number of threads in OpenMP.}
}
\value{
LightRFHyperparameters object.
}
\description{
Setup hyperparameters for LightRF training.
}
\details{
Get more information from \link[lightgbm:lgb.train]{lightgbm::lgb.train}.
Note that hyperparameters subsample_freq and early_stopping_rounds are fixed,
and cannot be set because they are what makes \code{lightgbm} train a random forest.
These can all be set when training gradient boosting with LightGBM.
}
\author{
EDG
}
