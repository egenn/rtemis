% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/linadleaves.R
\name{linadleaves}
\alias{linadleaves}
\title{\pkg{rtemis internal}: Low-level Stepwise Linear Additive Tree procedure}
\usage{
linadleaves(
  x,
  y,
  x.valid = NULL,
  y.valid = NULL,
  type,
  lookback = FALSE,
  weights = NULL,
  max.leaves = 5,
  gamleaves = FALSE,
  gamlearner = "s_GAMSEL",
  gam.params = list(degrees = 5),
  learning.rate = 1,
  minobsinnode.lin = 10,
  lin.type = "glmnet",
  first.lin.type = "glmnet",
  first.lin.learning.rate = 1,
  first.lin.alpha = 1,
  first.lin.lambda = NULL,
  gamma = 0.01,
  gamma.on.lin = FALSE,
  select.leaves.smooth = TRUE,
  alpha = 1,
  lambda = 0.01,
  lambda.seq = NULL,
  cv.glmnet.nfolds = 5,
  which.cv.glmnet.lambda = "lambda.1se",
  nvmax = 2,
  part.minsplit = 100,
  part.xval = 0,
  part.max.depth = 1,
  part.cp = 0,
  part.minbucket = 50,
  .rho = TRUE,
  rho.max = 1000,
  rho.def = 0.1,
  loss.fn = switch(type, Regression = mse, Classification = class.loss),
  verbose = TRUE,
  plot.tuning = TRUE,
  trace = 0
)
}
\arguments{
\item{x}{Data frame}

\item{y}{Numeric vector of outcome, i.e. dependent variable}

\item{lookback}{Logical: If TRUE, use validation error to decide best
number of leaves to use.}

\item{weights}{Numeric vector: Weights for cases. For classification, \code{weights} takes precedence
over \code{ipw}, therefore set \code{weights = NULL} if using \code{ipw}.
Note: If \code{weight} are provided, \code{ipw} is not used. Leave NULL if setting \code{ipw = TRUE}. Default = NULL}

\item{max.leaves}{Integer: Total number of terminal nodes to reach.
1 is a special case where no split is performed and a linear model is 
trained. Otherwise, this should be an even number as each split introduces 
two children nodes.}

\item{learning.rate}{[gS] Numeric: learning rate for steps after initial
linear model}

\item{minobsinnode.lin}{[gS] Integer: Minimum number of observation needed 
to fit linear model}

\item{lin.type}{Character: One of "glmnet", "forwardStepwise", "cv.glmnet", 
"lm.ridge", "allSubsets", "backwardStepwise", "glm", "solve", or "none"
to not fit linear models
See \link{lincoef} for more}

\item{first.lin.type}{Character: same options as \code{lin.type}, the first
linear model to fit on the root node.}

\item{first.lin.alpha}{Numeric: alpha for the first linear model, if
\code{first.lin.type} is "glmnet" or "cv.glmnet"}

\item{gamma}{[gS] Numeric: Soft weighting parameter. Weights of cases that 
do not belong to node get multiplied by this amount}

\item{lambda}{[gS] Numeric: lambda value for lin.type \code{glmnet}, 
\code{cv.glmnet}, \code{lm.ridge}}

\item{nvmax}{[gS] Integer: Number of max features to use for lin.type 
"allSubsets", "forwardStepwise", or "backwardStepwise". If values greater
than n of features in \code{x} are provided, they will be excluded}

\item{part.minsplit}{[gS] Integer: Minimum number of observations in node to
consider splitting}

\item{part.max.depth}{Integer: Max depth for each tree model within the 
additive tree}

\item{part.cp}{[gS] Numeric: Split must decrease complexity but at least 
this much to be considered}

\item{part.minbucket}{[gS] Integer: Minimum number of observations allowed in
child node to allow splitting}

\item{loss.fn}{Function with arguments \code{y, Fval }
Allows you to define a custom loss function. Defaults to \code{class.loss()} 
for classification and \code{mse()} for regression}

\item{verbose}{Logical: If TRUE, print summary to screen.}

\item{plot.tuning}{Logical: If TRUE, plot validation error during gridsearch}

\item{trace}{Integer: If higher than 0, will print more information to the console. Default = 0}
}
\description{
Train a Linear Additive Tree for Classification & Regression
}
\details{
With \code{max.nodes = 0}, the output is a linear model trained according to 
\code{lin.type}.
Note that lambda is treated differently by \code{glmnet::glmnet} and 
\code{MASS::lm.ridge}
}
\author{
E.D. Gennatas
}
\keyword{internal}
